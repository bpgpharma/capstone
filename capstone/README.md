# CAPSTONE PROJECT

Accurate facial recognition is important in law enforcement, national security, and social media [ref], but the current machine learning (ML) methods used regularly are imperfect [ref]. These algorithms work well on uniformly fully illuminated high contrast direct frontal face images [ref], and surely have increased success from constraining searches (prior knowledge) to a particular database (mugshots, circle of social media 'friends', watch lists) rather than to a pool of the population at large [ref]. Moreover, even given data sets trained with 'ideal' images, the methods stumble on the real world necessity of equivariance: the algorithms are not good at dealing with a view (image) that is not the same as the trained view [ref]. So a face in partial shadow, or rotated to a partial profile can result in a false negative (no identification) or false positive (wrong identification) [ref].

In this study, we take facial images from the publicly available databases Kaggle [ref], NIST-18 [ref], UCI [ref], and train them using two conventional ML algorithms - Support Vector Machine (SVM) widely used for image classification [ref], and Convolutional Neural Network (CNN) used with a SVM preprocessing step [ref], and then with the newly proposed Capsule Network (CapNet) [ref]. Then we input images of the same person taken from a different view than that with which the algorithm was trained to determine if the rate of true positives increases with statistical significance going from SVM to CNN to CapNet.
